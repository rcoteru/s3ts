{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtw_compute(dist_tensor: torch.Tensor, grad_tensor: torch.Tensor, w: float) -> None:\n",
    "    print(dist_tensor.shape)\n",
    "    for i in range(1, dist_tensor.shape[0]):\n",
    "        for j in range(1, dist_tensor.shape[1]):\n",
    "            value = torch.minimum(w * torch.minimum(dist_tensor[i, j-1], dist_tensor[i-1, j-1]), dist_tensor[i-1, j])\n",
    "            id = (w * dist_tensor[i, j-1] < dist_tensor[i-1, j]) & (dist_tensor[i, j-1] < dist_tensor[i-1, j-1])\n",
    "\n",
    "            dist_tensor[i, j] += value\n",
    "\n",
    "            grad_tensor[id][:, :, i, j] += w * grad_tensor[id][:, :, i, j-1]\n",
    "\n",
    "def torch_dtw_fast(x: torch.Tensor, y: torch.Tensor, w: float, eps: float = 1e-5):\n",
    "    # shape of x (n, dim, x_len) y (m, dim, y_len)\n",
    "\n",
    "    # performs convolution-like operation, for each kernel the DF\n",
    "    # (of shape (kernel_size, T)) is computed, then summed across channels\n",
    "    # x has shape (batch, c, time_dimension)\n",
    "\n",
    "    # compute pairwise diffs (squared)\n",
    "    p_diff = x[:,None,:,None,:] - y[None,:,:,:,None] # shape (n, n_kernel, d, Kernel_size, T)\n",
    "    euc_d = torch.square(p_diff).sum(2) # shape (n, n_kernel, kernel_size, T)\n",
    "\n",
    "    # p_diff contains the partial derivatives of DTW[n, k, i, j] wrt K[k, d, i] (dims (n, k, d, i, j))\n",
    "    p_diff = p_diff / torch.sqrt(euc_d[:,:, None, :, :] + eps)\n",
    "\n",
    "    # compute dtw\n",
    "    euc_d[:,:,0,:] = torch.cumsum(euc_d[:,:,0,:], dim=2)\n",
    "    euc_d[:,:,:,0] = torch.cumsum(euc_d[:,:,:,0], dim=2)\n",
    "\n",
    "    # rearrange dims\n",
    "    DTW = torch.permute(euc_d, (2, 3, 0, 1)).contiguous()\n",
    "\n",
    "    dtw_compute(DTW, p_diff, w)\n",
    "\n",
    "    # recover dimensions\n",
    "    DTW = torch.permute(DTW, (2, 3, 0, 1)).contiguous()\n",
    "\n",
    "    return DTW.sqrt(), p_diff\n",
    "\n",
    "class torch_dtw(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(x, y, w):\n",
    "        DTW, p_diff = torch_dtw_fast(x, y, w)\n",
    "        return DTW, p_diff\n",
    "    \n",
    "    @staticmethod\n",
    "    def setup_context(ctx, inputs, output):\n",
    "        DTW, p_diff = output\n",
    "        ctx.save_for_backward(p_diff)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, dtw_grad, p_diff_grad):\n",
    "        p_diff, = ctx.saved_tensors\n",
    "        mult = (p_diff * dtw_grad[:,:,None,:,:])\n",
    "        return mult.mean(dim=(1, 3)), mult.mean(dim=(0, 4)), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def dtw_compute2(dtw: torch.Tensor, dist_grad: torch.Tensor, w: float) -> torch.Tensor:\n",
    "    '''\n",
    "        dtw of shape (num_kernels, pattern_len, window_size)\n",
    "        dist_grad of shape (num_kernels, dims, pattern_len, window_size)\n",
    "        grad of shape (num_kernels, dims, pattern_len)\n",
    "    '''\n",
    "    grad = torch.empty(dtw.shape[0], dist_grad.shape[1], dtw.shape[1]) # shape (num_kernels, dims, pattern_len)\n",
    "    grads = torch.empty(dist_grad.shape[1], dtw.shape[1], dtw.shape[1], dtw.shape[2]) # shape (dims, pattern_len, pattern_len, window_size)\n",
    "\n",
    "    for k in range(dtw.shape[0]): # num_kernels\n",
    "        grads.zero_()\n",
    "\n",
    "        for i in range(dtw.shape[1]):\n",
    "            grads[:, i, i, :] = torch.cumsum(dist_grad[k, :, i, :], dim=1)\n",
    "            grads[:, i, i:, 0] = grads[:, i, i, :1]\n",
    "\n",
    "        for i in range(1, dtw.shape[1]): # wl\n",
    "            for j in range(1, dtw.shape[2]): # ws\n",
    "                value = torch.minimum(w * torch.minimum(dtw[k, i, j-1], dtw[k, i-1, j-1]), dtw[k, i-1, j])\n",
    "                temp_1 = dtw[k, i, j-1] < dtw[k, i-1, j-1] # path (i, j-1) or (i-1, j)\n",
    "                temp_2 = w * dtw[k, i, j-1] < dtw[k, i-1, j] # path (i, j-1) or (i-1, j-1)\n",
    "                temp_3 = w * dtw[k, i-1, j-1] < dtw[k, i-1, j] # path (i-1, j-1) or (i-1, j)\n",
    "\n",
    "                dtw[k, i, j] += value\n",
    "\n",
    "                if temp_1 and temp_2: # path is (i, j-1)\n",
    "                    grads[:, :, i, j] += w * grads[:, :, i, j-1]\n",
    "                elif temp_1 and temp_3: # path is (i-1, j)\n",
    "                    grads[:, :, i, j] += grads[:, :, i-1, j]\n",
    "                else: # path is (i-1, j-1)\n",
    "                    grads[:, :, i, j] += w * grads[:, :, i-1, j-1]\n",
    "\n",
    "        grad[k] += grads.sum(dim=(-2, -1))\n",
    "\n",
    "    return grad\n",
    "\n",
    "@torch.jit.script\n",
    "def torch_dtw_fast2(x: torch.Tensor, y: torch.Tensor, w: float, eps: float = 1e-5):\n",
    "    # shape of x (n, dim, x_len) y (m, dim, y_len)\n",
    "\n",
    "    # performs convolution-like operation, for each kernel the DF\n",
    "    # (of shape (kernel_size, T)) is computed, then summed across channels\n",
    "    # x has shape (batch, c, time_dimension)\n",
    "\n",
    "    # compute pairwise diffs (squared)\n",
    "    p_diff = x[:,None,:,None,:] - y[None,:,:,:,None] # shape (n, n_kernel, d, Kernel_size, T)\n",
    "    euc_d = torch.square(p_diff).sum(2) # shape (n, n_kernel, kernel_size, T)\n",
    "\n",
    "    # p_diff contains the partial derivatives of DTW[n, k, i, j] wrt K[k, d, i] (dims (n, k, d, i, j))\n",
    "    p_diff = p_diff / torch.sqrt(euc_d[:,:, None, :, :] + eps)\n",
    "\n",
    "    # compute dtw\n",
    "    euc_d[:,:,0,:] = torch.cumsum(euc_d[:,:,0,:], dim=2)\n",
    "    euc_d[:,:,:,0] = torch.cumsum(euc_d[:,:,:,0], dim=2)\n",
    "\n",
    "    futures : List[torch.jit.Future[torch.Tensor]] = []\n",
    "    for i in range(x.shape[0]):\n",
    "        futures.append(torch.jit.fork(dtw_compute2, euc_d[i], p_diff[i], w)) # euc_d (dtw) changed in place\n",
    "\n",
    "    results = [torch.jit.wait(future) for future in futures]\n",
    "\n",
    "    grads = torch.stack(results).sum(0)    \n",
    "\n",
    "    return euc_d.sqrt(), grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtw_compute2(dtw: torch.Tensor, dist_grad: torch.Tensor, grad: torch.Tensor, w: float) -> None:\n",
    "    '''\n",
    "        dtw of shape (num_kernels, pattern_len, window_size)\n",
    "        dist_grad of shape (num_kernels, dims, pattern_len, window_size)\n",
    "        grad of shape (num_kernels, dims, pattern_len)\n",
    "    '''\n",
    "    grads = torch.empty(dist_grad.shape[1], dtw.shape[1], dtw.shape[1], dtw.shape[2]) # shape (dims, pattern_len, pattern_len, window_size)\n",
    "    print(grads.numel())\n",
    "\n",
    "    for k in range(dtw.shape[0]): # num_kernels\n",
    "        grads.zero_()\n",
    "\n",
    "        for i in range(dtw.shape[1]):\n",
    "            grads[:, i, i, :] = torch.cumsum(dist_grad[k, :, i, :], dim=1)\n",
    "            grads[:, i, i:, 0] = grads[:, i, i, :1]\n",
    "\n",
    "        for i in range(1, dtw.shape[1]): # wl\n",
    "            for j in range(1, dtw.shape[2]): # ws\n",
    "                value = torch.minimum(w * torch.minimum(dtw[k, i, j-1], dtw[k, i-1, j-1]), dtw[k, i-1, j])\n",
    "                temp_1 = dtw[k, i, j-1] < dtw[k, i-1, j-1] # path (i, j-1) or (i-1, j)\n",
    "                temp_2 = w * dtw[k, i, j-1] < dtw[k, i-1, j] # path (i, j-1) or (i-1, j-1)\n",
    "                temp_3 = w * dtw[k, i-1, j-1] < dtw[k, i-1, j] # path (i-1, j-1) or (i-1, j)\n",
    "\n",
    "                dtw[k, i, j] += value\n",
    "\n",
    "                if temp_1 and temp_2: # path is (i, j-1)\n",
    "                    grads[:, :, i, j] += w * grads[:, :, i, j-1]\n",
    "                elif temp_1 and temp_3: # path is (i-1, j)\n",
    "                    grads[:, :, i, j] += grads[:, :, i-1, j]\n",
    "                else: # path is (i-1, j-1)\n",
    "                    grads[:, :, i, j] += w * grads[:, :, i-1, j-1]\n",
    "\n",
    "        grad[k] += grads.sum(dim=(-2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw = torch.randn(10, 15, 20)\n",
    "dist_grad = torch.randn(10, 6, 15, 20)\n",
    "grad = torch.randn(10, 6, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.0309e+01, -3.2442e+00, -1.3458e+01,  8.4600e+01, -1.1269e+01,\n",
       "           1.0207e+02, -6.2906e+00, -1.4982e+01, -6.4075e+00,  9.6667e+01,\n",
       "           1.1837e+02,  1.2234e+02, -2.3722e+00, -6.5837e+01, -4.9917e+01],\n",
       "         [ 6.3669e-01, -5.3787e+01,  1.2285e+01,  3.3467e+01,  2.7149e+00,\n",
       "           1.2115e+02,  4.8013e+00, -2.6668e+01, -1.7822e+01,  6.8604e+00,\n",
       "          -4.3326e+01, -3.2684e+01, -5.1875e+01, -4.6764e+01,  7.0709e-01],\n",
       "         [-1.6777e+01,  1.7212e+02,  7.3891e+01,  6.3038e+01,  5.5883e+01,\n",
       "          -4.7924e+01,  8.2706e+01, -5.7632e+00, -5.7387e+01, -8.4569e+01,\n",
       "           1.8049e+02,  5.5887e+02, -5.0924e-03,  2.7504e+01, -3.9577e+01],\n",
       "         [ 1.2510e+02, -3.6201e+01,  3.6084e+01, -1.4702e+01,  8.0949e+01,\n",
       "          -6.0405e+01,  3.1432e+01,  2.5460e+01, -1.9123e+01,  3.2267e+01,\n",
       "           8.9589e+00,  8.7169e+00, -2.6847e+01,  3.2196e+01,  8.5016e+00],\n",
       "         [ 1.8384e+01,  1.9731e+01, -7.6010e-01, -2.8320e+00,  2.4105e+01,\n",
       "           7.9186e+01, -1.0761e+02, -1.1195e+02, -1.3935e+02, -5.0808e+01,\n",
       "          -6.5393e+01,  5.0987e+01, -8.5074e+01, -1.3728e+01,  8.6020e+01],\n",
       "         [ 5.3778e+01, -9.3307e+01,  6.8745e+01,  4.5590e+01, -9.9575e+01,\n",
       "          -6.4932e+01, -3.7046e+01,  3.1746e+01, -1.4457e+02, -9.1189e+01,\n",
       "           6.5532e+01, -7.6896e+00,  2.4060e+00,  8.1604e+01, -1.8283e+01]],\n",
       "\n",
       "        [[ 1.2249e+02, -4.4979e+00, -1.3459e+02, -1.6852e+01,  2.5021e+01,\n",
       "          -6.0619e+01,  5.3045e+01,  3.1179e+01,  1.6457e+01,  3.8129e+01,\n",
       "           3.1246e+01,  8.2838e+01,  8.0846e+01,  1.0833e+02,  6.1542e+02],\n",
       "         [ 7.2649e+01,  2.2404e+01,  1.9065e+02, -2.9426e+01,  9.7422e+01,\n",
       "          -2.6031e+01, -4.8490e+01, -2.6634e+01,  8.2205e+01,  3.3999e+01,\n",
       "           5.2982e+01,  9.0760e+00, -3.0735e+01, -9.2678e+00, -3.5996e+01],\n",
       "         [ 3.2167e+01, -4.3409e+00,  3.2033e+01,  7.2894e+01,  4.6249e+01,\n",
       "           8.3349e+00, -2.3240e+01,  4.3925e+01, -1.2014e+02, -1.7694e+01,\n",
       "          -1.7671e+01,  1.2013e+02, -9.7430e+01,  1.5410e+01, -4.4127e+00],\n",
       "         [ 9.4515e+01,  1.2310e+01, -1.0493e+02, -1.0304e+01,  6.1567e+01,\n",
       "          -4.4590e+01,  1.2131e+02, -2.5799e+00, -3.3894e+01, -1.8546e+01,\n",
       "           2.5137e+01, -4.1410e+01,  6.3493e+01,  3.2421e+01,  5.1777e+01],\n",
       "         [ 6.8446e+01,  2.2303e+01,  4.7921e+01, -5.0234e+01, -6.2328e+01,\n",
       "          -1.1069e+01, -1.7445e+02,  3.1672e+01,  7.5046e+01,  3.1835e+01,\n",
       "           7.4602e+01,  7.5464e+01, -8.5162e+01,  3.8220e+01, -2.1686e+01],\n",
       "         [-1.9328e+01, -1.6556e+02, -7.6329e+01,  9.0672e+01,  1.1468e+02,\n",
       "          -3.6383e+01,  6.6013e+01,  4.6236e+00,  1.9693e+01,  1.5837e+02,\n",
       "          -1.0444e+01, -3.0252e+01,  3.9308e+01, -7.1651e+00, -6.0596e+01]],\n",
       "\n",
       "        [[-1.0272e+02, -8.3652e+01, -1.1426e+02,  3.6419e+01,  6.3614e+01,\n",
       "          -2.8375e+01,  4.0670e+00, -6.0383e+00, -4.0543e-01,  9.2376e+01,\n",
       "           1.1020e+02, -1.0000e+01,  1.1547e+01,  2.4186e+01, -7.1661e+00],\n",
       "         [-7.2128e+01, -5.3687e+01, -4.2259e+01, -2.3422e+01, -9.0158e+01,\n",
       "          -3.8318e+01, -2.3089e+01,  1.7154e+00, -1.8751e+01, -7.7274e+01,\n",
       "          -2.2631e+00, -2.0264e+01, -4.8118e+01, -6.7135e+01, -6.2893e+01],\n",
       "         [-6.7394e+01,  9.0006e+01,  9.8463e+01,  7.0616e+01,  3.1624e+00,\n",
       "          -6.4052e+01, -2.3492e+00,  8.7693e+01, -1.0060e+02, -8.6663e+01,\n",
       "           3.3597e+01, -7.0824e+01,  1.3509e+02, -1.9558e+01, -2.5072e+01],\n",
       "         [-4.1842e+00, -7.3118e-01, -3.3972e+01, -1.0441e+01,  2.6211e+01,\n",
       "          -2.3524e+01,  9.6518e+00,  2.4736e+02,  8.8803e+01,  1.4589e+01,\n",
       "          -2.1930e+01, -3.2252e+01,  4.9226e+01,  7.1722e+01, -1.4308e+01],\n",
       "         [ 9.9758e+01, -2.3185e+01,  6.4887e+01, -9.0711e+01, -6.3091e+01,\n",
       "           7.1501e+01, -5.2150e+01, -1.2911e+01, -1.0171e+02,  8.1873e+01,\n",
       "           4.2294e+01, -7.6803e+01,  5.2291e+01, -4.5956e+01,  6.2721e+01],\n",
       "         [ 3.1315e-01,  3.5375e+01, -1.5072e+01,  7.6645e+01,  1.6702e+01,\n",
       "          -4.7953e+01, -8.4904e+01,  6.8852e+01,  5.0676e+01,  3.4376e+00,\n",
       "           5.8394e+01,  1.0197e+02,  4.9033e+00, -3.5170e+01,  2.4545e+01]],\n",
       "\n",
       "        [[ 1.1278e+02,  2.4024e+00, -6.8719e-01, -1.1333e+02,  1.1485e+01,\n",
       "           5.1976e+01, -6.1635e+01, -2.7387e+01, -6.3207e+01, -1.1993e+01,\n",
       "           5.3099e+00,  4.8590e+01, -4.4904e+01,  1.2939e+02, -5.5139e+01],\n",
       "         [ 3.7238e+01, -1.3556e+01,  8.6055e+00, -1.0824e+02,  6.9260e+01,\n",
       "          -3.3620e+01,  7.2437e+01,  1.5950e+01,  7.2410e+01, -5.7171e+00,\n",
       "           1.0176e+00,  1.5980e+02,  7.1274e+01, -4.0170e+00,  8.2270e-01],\n",
       "         [-1.1336e+01, -1.5681e+02,  7.6040e+01, -1.0954e+01,  1.0694e+02,\n",
       "          -1.6774e+01,  4.9850e+00,  4.6064e+00, -4.1210e+01, -4.6890e+00,\n",
       "           6.7037e+01, -5.4553e+01, -1.0926e+02, -1.6451e+01, -2.1331e+01],\n",
       "         [ 5.0147e+01,  3.3635e+01,  1.3688e+02,  9.7751e-01,  6.2615e+01,\n",
       "           9.2369e+01,  3.8632e+01,  1.3740e+02,  1.2069e+02,  1.3679e+01,\n",
       "           5.0985e+01, -9.4921e+01,  2.2662e+01,  5.6319e+01, -3.4332e+01],\n",
       "         [ 2.7449e+01,  1.5929e+01,  5.6794e+01,  6.2776e+01,  1.0746e+02,\n",
       "          -2.9552e+01,  3.4477e+01, -3.3050e+00, -7.3487e+01, -8.1554e+01,\n",
       "          -1.3130e+01,  5.3029e+01, -4.4260e+01, -1.0421e+02,  3.5808e+01],\n",
       "         [ 4.4195e+01, -1.0803e+02,  1.3780e+02,  1.2467e+02, -3.5190e+01,\n",
       "           6.8083e+01, -1.6073e+02,  7.9146e+01, -2.7181e+01,  2.4443e+01,\n",
       "           5.2203e+01,  9.8076e+01, -1.4050e+02,  1.0381e+02,  5.3101e+01]],\n",
       "\n",
       "        [[ 1.1247e+02,  3.0371e+02,  7.3836e+01, -4.8594e+01,  1.1429e+02,\n",
       "           9.4867e+00,  3.0316e+01, -3.6190e+01, -3.4258e+01, -1.4554e+01,\n",
       "           1.7403e+01, -4.3597e+01,  2.0456e+01,  1.1983e+01, -1.8630e+01],\n",
       "         [ 7.0578e+01, -1.0763e+00,  3.5916e+01, -2.1598e+01, -1.0028e+02,\n",
       "           2.9404e+01,  1.0057e+02,  2.7046e+01,  3.8764e+01,  7.2372e-01,\n",
       "          -1.0781e+02,  6.1009e+01, -3.7736e+01, -4.2751e+01, -5.2498e+01],\n",
       "         [ 5.1610e+01,  7.4234e+01, -2.1230e+02, -4.3894e+01,  2.3235e+00,\n",
       "           1.9481e+01,  6.7340e+01, -7.5106e+01,  4.1620e+01,  1.1497e+01,\n",
       "           1.7056e+01, -1.2676e+02,  4.7026e+00,  3.9592e+01, -5.4621e+01],\n",
       "         [-2.8879e+01,  1.5076e+01,  6.9722e+01, -7.7289e+01, -1.2639e+01,\n",
       "          -2.0066e+00,  4.2014e+01, -4.6749e+00,  1.7580e+01, -3.7160e+01,\n",
       "          -1.3967e+01,  1.7354e+01, -1.6403e+01, -1.3171e+02,  5.4161e+00],\n",
       "         [ 4.0791e+01, -6.3823e+01, -7.7787e+01,  9.3974e+00,  3.6048e+02,\n",
       "           4.2728e+01,  3.0049e+00,  4.6329e+01, -1.1525e+02, -1.9651e+02,\n",
       "           8.7370e+01, -1.2055e+01,  3.7465e+01,  2.1507e+01, -6.7889e+01],\n",
       "         [ 3.0241e+01, -3.3808e+00,  3.1361e+01, -1.8604e+01,  1.1133e+02,\n",
       "           1.2430e+01, -3.2089e-01,  1.1862e+01,  8.9526e+01, -1.4183e+01,\n",
       "           6.8876e+01,  2.0887e+01,  1.5519e+01, -3.9585e+01, -2.1472e+01]],\n",
       "\n",
       "        [[ 2.7053e+01,  2.3061e+01,  5.3155e+01,  4.8825e+01,  9.7922e+01,\n",
       "           4.7681e+01,  9.3591e+01,  1.4941e+01,  3.0461e+01,  2.3550e-01,\n",
       "          -2.2551e+01,  4.8332e+01, -3.4548e+01, -1.1361e+02, -1.6205e+01],\n",
       "         [-3.2012e+01, -3.6341e+01, -8.0884e+00,  3.3555e+01, -2.4730e+01,\n",
       "           4.5997e+01,  1.4294e+02,  1.2805e+01, -4.5306e+01, -6.5597e+01,\n",
       "          -1.6200e+01,  7.2670e+01, -2.4763e+01,  1.4287e+02, -9.2663e+01],\n",
       "         [-6.2203e+01,  1.0802e+01,  1.6988e+02, -1.7857e+01, -1.4967e+01,\n",
       "          -2.4963e+01, -6.6497e+01,  2.8446e+01,  2.3589e+02,  1.0487e+02,\n",
       "           3.0784e+01,  1.4131e+01, -7.7767e+01, -7.0404e+00,  1.2042e+02],\n",
       "         [ 3.3020e+01, -1.0571e+02, -4.8076e+01,  1.4178e+01,  2.0080e+01,\n",
       "          -7.2880e+01, -8.0082e+01, -4.5947e+01,  5.2668e+01,  6.1653e+01,\n",
       "           6.7191e+00,  4.3950e+01,  5.8481e+01,  9.0475e+01,  9.5785e+01],\n",
       "         [ 1.1448e+02,  7.2597e+01, -8.4657e+01,  3.4183e+01, -4.4430e+01,\n",
       "          -4.8183e+00, -5.4005e+01,  6.6565e+01,  1.9927e+02,  6.7100e+00,\n",
       "          -1.0446e+01,  5.2766e+01, -4.6472e+01, -4.5251e+01,  1.1478e+02],\n",
       "         [-1.1581e+02, -5.1360e+00, -8.3903e+01, -1.4839e+01, -1.0263e+02,\n",
       "           1.3406e+01, -7.1234e+01,  8.2225e+01, -7.1155e+01,  2.7583e+01,\n",
       "           1.1122e+02,  1.0641e+02, -4.5698e+01, -3.3191e+01, -9.0183e+00]],\n",
       "\n",
       "        [[-3.8196e+01, -1.2549e+02, -5.2039e+01, -1.3133e+02, -5.7689e+01,\n",
       "           1.2811e+02, -6.6679e+00, -3.2690e+01, -1.1210e+01, -5.9437e+01,\n",
       "          -4.1261e+00,  2.8748e+01,  1.5746e+02,  1.7666e+01, -4.5043e+01],\n",
       "         [ 5.0176e+01, -1.8193e+02,  1.6667e+01, -8.9404e+00, -1.9515e+01,\n",
       "           6.3431e+00, -1.2666e+02, -2.9393e+01, -2.8604e+01, -1.8720e+01,\n",
       "          -3.6534e+01, -5.1541e+01, -1.9005e+01, -4.1194e+01,  3.3796e+01],\n",
       "         [-1.1499e+01,  2.4235e+01, -7.1707e+01, -7.1460e+00,  3.7099e+01,\n",
       "           7.4635e+01,  7.9913e+01,  5.4505e+01, -1.8214e+01, -2.5274e+01,\n",
       "          -4.4262e+01, -2.2884e+01,  7.8062e+00,  1.5955e+01, -1.3859e+02],\n",
       "         [ 7.0479e+01,  1.8514e+00, -2.9131e+01,  3.5055e+01, -1.7464e+02,\n",
       "          -9.4349e+01,  4.5188e+01,  3.7874e+01,  2.3870e+01, -8.6965e+01,\n",
       "           1.3893e+02, -1.0587e+02, -9.2722e+00,  6.7706e+01,  7.3084e+01],\n",
       "         [ 1.6299e+02, -9.3151e+00, -1.5241e+01, -1.0468e+01, -9.1046e+00,\n",
       "          -1.6315e+01,  1.2814e+02,  8.2886e+01,  8.5916e+01,  9.3039e+01,\n",
       "           9.1324e+01,  8.3930e+01,  9.8826e+01,  2.6278e+01, -2.4338e+01],\n",
       "         [-6.3435e+01,  2.0655e+02,  4.0368e+02,  5.6124e+01, -1.1857e+02,\n",
       "          -2.5577e+01,  7.6848e+01,  3.2299e+00,  8.8705e+00, -6.3534e+01,\n",
       "           2.3270e+01,  5.5186e+00,  1.2333e+02,  8.5792e+01, -2.4795e+01]],\n",
       "\n",
       "        [[-4.8129e+01,  4.6744e+01,  1.4275e+02,  7.8381e+00,  6.0749e+01,\n",
       "          -3.8993e+01,  5.9840e+01, -1.0659e+01,  2.0315e+00, -2.1976e+01,\n",
       "           1.2599e+01, -2.6424e+01,  4.1418e+01, -2.0702e+01,  7.2922e+00],\n",
       "         [-3.1492e+01,  2.2288e+01,  4.8156e+01,  7.9250e+00,  4.4062e+01,\n",
       "          -7.4852e+01,  7.0459e+01, -6.3742e+00,  1.2847e+01,  6.7724e+01,\n",
       "           1.0159e+02,  1.4029e+01,  2.7027e+01,  2.6864e+01,  2.4265e+01],\n",
       "         [-3.4645e+01,  1.9334e+02,  5.8189e+01, -5.0858e+01, -2.5928e+01,\n",
       "           2.6351e+01, -1.7292e+02,  2.2493e+01,  1.1061e+02, -1.8357e+01,\n",
       "           2.5403e+01,  6.5106e+01, -2.8466e+01,  9.8572e+01, -2.2504e+01],\n",
       "         [-4.6694e+01, -3.3353e+01, -2.7709e+01, -2.9055e+01,  4.9120e+01,\n",
       "           3.6435e+01,  1.7053e+02,  4.4546e+01,  3.5183e+00, -1.2549e+01,\n",
       "           1.5840e+01,  6.6660e+01,  6.8300e+01, -1.3169e+01, -8.1359e+00],\n",
       "         [-1.0202e+01, -2.3444e+01, -5.4270e+01,  3.9341e+01,  6.6394e+01,\n",
       "           2.7670e+01, -1.0670e+02, -2.3532e+01, -1.2736e+01,  4.3414e+01,\n",
       "          -4.6764e+01, -1.4606e+02, -5.5915e+01, -5.6328e+01,  5.2525e+01],\n",
       "         [-1.6224e+00, -5.7639e+01,  3.2719e+01,  4.3614e+01,  3.6798e+00,\n",
       "          -7.7464e+01, -1.2981e+01,  1.0009e+01,  1.5689e+01, -6.8241e+01,\n",
       "          -6.8424e+01, -6.0182e+01,  9.6765e+01,  1.0187e+02, -1.4374e+00]],\n",
       "\n",
       "        [[ 1.0292e+02,  3.2038e+01, -3.3410e+01, -1.3297e+02, -2.7402e+01,\n",
       "          -3.4978e+00, -3.9595e+00,  8.0743e-01, -3.6807e+01,  7.3014e+01,\n",
       "          -2.9365e+00,  2.9759e+01,  3.1246e+01,  3.6282e+01,  8.9469e+01],\n",
       "         [-1.3829e+02,  5.3669e+01,  1.0070e+02, -7.0903e+01,  4.7509e+01,\n",
       "          -4.7069e+01, -4.9452e+00,  2.8878e+01, -1.1610e+01,  7.9650e+01,\n",
       "           2.3562e+01, -7.5721e+01, -6.3693e+01, -5.3693e+01, -7.5988e+01],\n",
       "         [ 7.5491e+01, -1.3051e+02, -8.7105e+01, -6.7312e+01,  5.2743e+01,\n",
       "           1.5972e+00,  6.0110e+01, -2.6922e+00, -2.9971e+01, -1.2546e+02,\n",
       "           5.7462e+01,  7.8159e+01, -5.6414e+01,  3.8871e+01,  9.4023e+01],\n",
       "         [-5.8766e+00, -1.6311e+00, -1.6456e+01,  4.6961e+01, -4.4704e+01,\n",
       "           7.4863e+01, -1.2590e+02, -3.2793e+01, -3.6137e+00,  2.9412e+01,\n",
       "           1.0531e+02, -4.7188e+01, -8.5329e+00,  2.6421e+01,  2.9455e+01],\n",
       "         [-5.3702e+01,  1.4828e+02,  8.8587e+00,  6.4509e+01,  2.7963e+01,\n",
       "          -3.7683e+01, -1.3098e+01, -1.6868e+01, -5.2750e+01,  3.9297e+01,\n",
       "          -2.0121e+01,  1.0064e+01,  5.2878e+01,  4.6651e+01, -6.6582e+01],\n",
       "         [-6.4536e+01, -2.2311e+01,  9.0516e+01,  6.9626e+00, -2.2342e+01,\n",
       "          -6.9779e+01, -5.7310e+01,  7.1821e+01,  8.3457e+01,  4.0403e+01,\n",
       "          -1.4493e+01,  3.0558e+01, -3.3243e+01,  1.0043e+02,  4.5466e+02]],\n",
       "\n",
       "        [[-3.3735e+01, -5.7600e+01, -7.6401e+01, -4.8452e+01,  3.7067e+01,\n",
       "          -3.4969e+01, -3.2602e+01, -2.2435e+01,  4.7617e+01,  1.2407e+02,\n",
       "          -8.8463e+00, -4.1114e+01,  1.1322e+02, -9.4960e+00,  2.1009e+01],\n",
       "         [ 1.3286e+01, -7.3751e+01,  3.5050e+01, -1.9572e+01, -6.3316e+01,\n",
       "           8.2880e+01, -5.0033e+01,  4.7070e+01,  4.3343e+01, -2.3929e+01,\n",
       "          -7.9014e+00,  3.0254e+00,  8.1774e+01, -6.2404e+01, -4.7373e+01],\n",
       "         [-3.9072e+01, -1.0343e+02,  1.1396e+02, -1.0229e+02,  9.1128e+01,\n",
       "           1.1477e+01,  1.3860e+02, -1.8080e+01,  6.2430e+01, -5.5939e+01,\n",
       "           5.1684e+00, -1.1761e+02, -1.4062e+02, -2.4420e+01,  1.7608e+01],\n",
       "         [ 1.4437e+02, -1.4971e+01,  7.5516e+01, -6.8212e+00,  7.2558e+01,\n",
       "          -8.6819e+00, -2.4883e+01, -2.8579e+01, -5.9768e+01,  1.4997e+02,\n",
       "           1.3283e+02,  6.3239e+00, -1.8144e+01, -5.1820e+00, -3.9964e+01],\n",
       "         [-1.1177e+02, -2.1764e+01,  1.8675e+02,  1.7310e+02, -6.6776e+01,\n",
       "           4.7230e+01,  2.3610e+01, -6.9978e+01, -3.0319e+00,  8.6989e+01,\n",
       "           4.4598e+01, -9.4488e+01, -7.1854e+01,  1.8696e+02,  2.6532e+01],\n",
       "         [ 1.5449e+01, -1.2435e+02,  3.4319e+00, -9.4236e+01,  6.0561e+00,\n",
       "           1.7494e+01,  3.0712e+01,  3.1216e+01,  3.5082e+00, -1.3379e+02,\n",
       "          -1.1188e+01,  1.7530e+01,  3.2389e+01,  8.1597e+00, -3.5766e+01]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtw_compute2(dtw, dist_grad, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10, 3, 20)\n",
    "y = torch.randn(15, 3, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add1(x):\n",
    "    x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = torch_dtw_fast2(x, y, w=0.01, eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 20, 10, 15])\n"
     ]
    }
   ],
   "source": [
    "a1, b1  = torch_dtw_fast(x, y, w=0.01, eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37748736"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.numel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssstsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
