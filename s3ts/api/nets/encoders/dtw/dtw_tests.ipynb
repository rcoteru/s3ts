{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtw_compute(dist_tensor: torch.Tensor, grad_tensor: torch.Tensor, w: float) -> None:\n",
    "    print(dist_tensor.shape)\n",
    "    for i in range(1, dist_tensor.shape[0]):\n",
    "        for j in range(1, dist_tensor.shape[1]):\n",
    "            value = torch.minimum(w * torch.minimum(dist_tensor[i, j-1], dist_tensor[i-1, j-1]), dist_tensor[i-1, j])\n",
    "            id = (w * dist_tensor[i, j-1] < dist_tensor[i-1, j]) & (dist_tensor[i, j-1] < dist_tensor[i-1, j-1])\n",
    "\n",
    "            dist_tensor[i, j] += value\n",
    "\n",
    "            grad_tensor[id][:, :, i, j] += w * grad_tensor[id][:, :, i, j-1]\n",
    "\n",
    "def torch_dtw_fast(x: torch.Tensor, y: torch.Tensor, w: float, eps: float = 1e-5):\n",
    "    # shape of x (n, dim, x_len) y (m, dim, y_len)\n",
    "\n",
    "    # performs convolution-like operation, for each kernel the DF\n",
    "    # (of shape (kernel_size, T)) is computed, then summed across channels\n",
    "    # x has shape (batch, c, time_dimension)\n",
    "\n",
    "    # compute pairwise diffs (squared)\n",
    "    p_diff = x[:,None,:,None,:] - y[None,:,:,:,None] # shape (n, n_kernel, d, Kernel_size, T)\n",
    "    euc_d = torch.square(p_diff).sum(2) # shape (n, n_kernel, kernel_size, T)\n",
    "\n",
    "    # p_diff contains the partial derivatives of DTW[n, k, i, j] wrt K[k, d, i] (dims (n, k, d, i, j))\n",
    "    p_diff = p_diff / torch.sqrt(euc_d[:,:, None, :, :] + eps)\n",
    "\n",
    "    # compute dtw\n",
    "    euc_d[:,:,0,:] = torch.cumsum(euc_d[:,:,0,:], dim=2)\n",
    "    euc_d[:,:,:,0] = torch.cumsum(euc_d[:,:,:,0], dim=2)\n",
    "\n",
    "    # rearrange dims\n",
    "    DTW = torch.permute(euc_d, (2, 3, 0, 1)).contiguous()\n",
    "\n",
    "    dtw_compute(DTW, p_diff, w)\n",
    "\n",
    "    # recover dimensions\n",
    "    DTW = torch.permute(DTW, (2, 3, 0, 1)).contiguous()\n",
    "\n",
    "    return DTW.sqrt(), p_diff\n",
    "\n",
    "class torch_dtw(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(x, y, w):\n",
    "        DTW, p_diff = torch_dtw_fast(x, y, w)\n",
    "        return DTW, p_diff\n",
    "    \n",
    "    @staticmethod\n",
    "    def setup_context(ctx, inputs, output):\n",
    "        DTW, p_diff = output\n",
    "        ctx.save_for_backward(p_diff)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, dtw_grad, p_diff_grad):\n",
    "        p_diff, = ctx.saved_tensors\n",
    "        mult = (p_diff * dtw_grad[:,:,None,:,:])\n",
    "        return mult.mean(dim=(1, 3)), mult.mean(dim=(0, 4)), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def dtw_compute2(dtw: torch.Tensor, dist_grad: torch.Tensor, grad: torch.Tensor, w: float) -> None:\n",
    "    '''\n",
    "        dtw of shape (n, pattern_len, window_size)\n",
    "        dist_grad of shape (n, dims, pattern_len, window_size)\n",
    "        grad of shape (dims, pattern_len)\n",
    "    '''\n",
    "    grads = torch.zeros(dtw.shape[0], dist_grad.shape[1], dtw.shape[1], dtw.shape[1], dtw.shape[2]) # shape (n, dims, pattern_len, pattern_len, window_size)\n",
    "\n",
    "    for i in range(dtw.shape[1]):\n",
    "        grads[:, :, i, i, :] = torch.cumsum(dist_grad[:, :, i, :], dim=2)\n",
    "        grads[:, :, i, i:, 0] = grads[:, :, i, i, :1]\n",
    "\n",
    "    for i in range(1, dtw.shape[1]): # pl\n",
    "        for j in range(1, dtw.shape[2]): # ws\n",
    "            value = torch.minimum(w * torch.minimum(dtw[:, i, j-1], dtw[:, i-1, j-1]), dtw[:, i-1, j])\n",
    "            temp_1 = dtw[:, i, j-1] < dtw[:, i-1, j-1] # path (i, j-1) or (i-1, j)\n",
    "            temp_2 = w * dtw[:, i, j-1] < dtw[:, i-1, j] # path (i, j-1) or (i-1, j-1)\n",
    "            temp_3 = w * dtw[:, i-1, j-1] < dtw[:, i-1, j] # path (i-1, j-1) or (i-1, j)\n",
    "\n",
    "            dtw[:, i, j] += value\n",
    "\n",
    "            grads[temp_1 & temp_2][:, :, i, j] += w * grads[temp_1 & temp_2][:, :, i, j-1]\n",
    "            grads[temp_1 & temp_3][:, :, i, j] += grads[temp_1 & temp_3][:, :, i-1, j]\n",
    "            grads[temp_2 & temp_3][:, :, i, j] += w * grads[temp_2 & temp_3][:, :, i-1, j-1]\n",
    "\n",
    "    grad = grads.sum(dim=(0, -2, -1))\n",
    "\n",
    "@torch.jit.script\n",
    "def torch_dtw_fast2(x: torch.Tensor, y: torch.Tensor, w: float, eps: float = 1e-5):\n",
    "    # shape of x (n, dim, x_len) y (m, dim, y_len)\n",
    "\n",
    "    # performs convolution-like operation, for each kernel the DF\n",
    "    # (of shape (kernel_size, T)) is computed, then summed across channels\n",
    "    # x has shape (batch, c, time_dimension)\n",
    "\n",
    "    # compute pairwise diffs (squared)\n",
    "    p_diff = x[:,None,:,None,:] - y[None,:,:,:,None] # shape (n, n_kernel, d, Kernel_size, T)\n",
    "    euc_d = torch.square(p_diff).sum(2) # shape (n, n_kernel, kernel_size, T)\n",
    "\n",
    "    # p_diff now contains the partial derivatives of DTW[n, k, i, j] wrt K[k, d, i] (dims (n, k, d, i, j))\n",
    "    p_diff = p_diff / torch.sqrt(euc_d[:,:, None, :, :] + eps)\n",
    "\n",
    "    # compute dtw\n",
    "    euc_d[:,:,0,:] = torch.cumsum(euc_d[:,:,0,:], dim=2)\n",
    "    euc_d[:,:,:,0] = torch.cumsum(euc_d[:,:,:,0], dim=2)\n",
    "\n",
    "    grads = torch.empty(y.shape[0], y.shape[1], y.shape[2])\n",
    "\n",
    "    futures = [torch.jit.fork(dtw_compute2, euc_d[:, i], p_diff[:, i], grads[i], w) for i in range(y.shape[0])] # iterate through k\n",
    "    results = [torch.jit.wait(future) for future in futures]\n",
    "\n",
    "    return euc_d.sqrt(), grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtw_compute2(dtw: torch.Tensor, dist_grad: torch.Tensor, grad: torch.Tensor, w: float) -> None:\n",
    "    '''\n",
    "        dtw of shape (num_kernels, pattern_len, window_size)\n",
    "        dist_grad of shape (num_kernels, dims, pattern_len, window_size)\n",
    "        grad of shape (num_kernels, dims, pattern_len)\n",
    "    '''\n",
    "    grads = torch.empty(dist_grad.shape[1], dtw.shape[1], dtw.shape[1], dtw.shape[2]) # shape (dims, pattern_len, pattern_len, window_size)\n",
    "    print(grads.numel())\n",
    "\n",
    "    for k in range(dtw.shape[0]): # num_kernels\n",
    "        grads.zero_()\n",
    "\n",
    "        for i in range(dtw.shape[1]):\n",
    "            grads[:, i, i, :] = torch.cumsum(dist_grad[k, :, i, :], dim=1)\n",
    "            grads[:, i, i:, 0] = grads[:, i, i, :1]\n",
    "\n",
    "        for i in range(1, dtw.shape[1]): # wl\n",
    "            for j in range(1, dtw.shape[2]): # ws\n",
    "                value = torch.minimum(w * torch.minimum(dtw[k, i, j-1], dtw[k, i-1, j-1]), dtw[k, i-1, j])\n",
    "                temp_1 = dtw[k, i, j-1] < dtw[k, i-1, j-1] # path (i, j-1) or (i-1, j)\n",
    "                temp_2 = w * dtw[k, i, j-1] < dtw[k, i-1, j] # path (i, j-1) or (i-1, j-1)\n",
    "                temp_3 = w * dtw[k, i-1, j-1] < dtw[k, i-1, j] # path (i-1, j-1) or (i-1, j)\n",
    "\n",
    "                dtw[k, i, j] += value\n",
    "\n",
    "                if temp_1 and temp_2: # path is (i, j-1)\n",
    "                    grads[:, :, i, j] += w * grads[:, :, i, j-1]\n",
    "                elif temp_1 and temp_3: # path is (i-1, j)\n",
    "                    grads[:, :, i, j] += grads[:, :, i-1, j]\n",
    "                else: # path is (i-1, j-1)\n",
    "                    grads[:, :, i, j] += w * grads[:, :, i-1, j-1]\n",
    "\n",
    "        grad[k] += grads.sum(dim=(-2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw = torch.randn(10, 15, 20)\n",
    "dist_grad = torch.randn(10, 6, 15, 20)\n",
    "grad = torch.randn(10, 6, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(128, 3, 50)\n",
    "y = torch.randn(30, 3, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = torch_dtw_fast2(x, y, w=0.01, eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5491e+03,  4.5797e-41, -1.5491e+03,  ...,  3.4672e+02,\n",
       "           3.4989e+02,  3.5448e+02],\n",
       "         [ 4.5532e+00,  6.5410e+00,  1.2868e+01,  ...,  1.6305e+02,\n",
       "           1.6331e+02,  1.6849e+02],\n",
       "         [ 2.9943e+00,  1.2709e+01,  1.4772e+01,  ...,  2.6251e+02,\n",
       "           2.6573e+02,  2.7669e+02]],\n",
       "\n",
       "        [[ 2.2421e+00,  6.5757e+00,  1.1365e+01,  ...,  1.6096e+02,\n",
       "           1.6152e+02,  1.6964e+02],\n",
       "         [ 1.1992e+01,  1.8119e+01,  2.7265e+01,  ...,  3.8746e+02,\n",
       "           3.9177e+02,  3.9182e+02],\n",
       "         [ 1.0636e+01,  1.3831e+01,  2.0374e+01,  ...,  2.8675e+02,\n",
       "           2.8934e+02,  2.9000e+02]],\n",
       "\n",
       "        [[ 7.8894e+00,  1.1039e+01,  2.5231e+01,  ...,  3.2383e+02,\n",
       "           3.2714e+02,  3.3771e+02],\n",
       "         [ 5.5964e+00,  8.5314e+00,  1.9136e+01,  ...,  2.3628e+02,\n",
       "           2.3762e+02,  2.4319e+02],\n",
       "         [ 1.3051e+01,  1.6404e+01,  1.8966e+01,  ...,  3.0877e+02,\n",
       "           3.1271e+02,  3.1660e+02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.5028e+01,  3.9858e+01,  5.4796e+01,  ...,  6.0825e+02,\n",
       "           6.2421e+02,  6.2829e+02],\n",
       "         [ 2.2936e+00,  6.7252e+00,  7.8589e+00,  ...,  2.1175e+02,\n",
       "           2.1605e+02,  2.2476e+02],\n",
       "         [ 3.7539e+00,  2.0676e+01,  3.0110e+01,  ...,  3.6065e+02,\n",
       "           3.7137e+02,  3.7756e+02]],\n",
       "\n",
       "        [[ 8.2604e+00,  2.7074e+01,  3.6538e+01,  ...,  3.8001e+02,\n",
       "           3.9043e+02,  3.9289e+02],\n",
       "         [ 6.9017e-01,  6.4169e+00,  9.0623e+00,  ...,  1.7415e+02,\n",
       "           1.8008e+02,  1.8595e+02],\n",
       "         [ 1.6254e+00,  1.7255e+01,  2.3485e+01,  ...,  2.9368e+02,\n",
       "           3.0012e+02,  3.0771e+02]],\n",
       "\n",
       "        [[ 2.7395e+00,  1.3665e+01,  1.5264e+01,  ...,  2.3227e+02,\n",
       "           2.3426e+02,  2.4237e+02],\n",
       "         [ 3.2985e-01,  8.5776e+00,  1.1160e+01,  ...,  1.8711e+02,\n",
       "           1.9167e+02,  1.9850e+02],\n",
       "         [ 7.6547e+00,  2.0712e+01,  2.5624e+01,  ...,  2.5910e+02,\n",
       "           2.6568e+02,  2.6641e+02]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 20, 10, 15])\n"
     ]
    }
   ],
   "source": [
    "a1, b1  = torch_dtw_fast(x, y, w=0.01, eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37748736"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.numel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssstsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
