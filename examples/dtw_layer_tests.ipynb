{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from s3ts.data.stsdataset import STSDataset, LSTSDataset, StreamingTimeSeries\n",
    "from s3ts.api.nets.encoders.dtw.dtw_layer import DTWLayer\n",
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 'BasicMotions' from cache...\n",
      "(80, 6, 100) (80,) 4\n",
      "(6, 6000) (6000,)\n"
     ]
    }
   ],
   "source": [
    "from s3ts.api.ucr import load_ucr_classification\n",
    "from s3ts.api.ts2sts import fin_random_STS\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "X, Y, mapping = load_ucr_classification(\"BasicMotions\")\n",
    "#X, Y, mapping = load_ucr_classification(\"GunPoint\")\n",
    "print(X.shape, Y.shape, len(np.unique(Y)))\n",
    "\n",
    "STS, SCS = fin_random_STS(X, Y, length=60)\n",
    "print(STS.shape, SCS.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = StreamingTimeSeries(STS, SCS, wsize=32, wstride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_shuffled = np.arange(ds.indices.shape[0])[:5000]\n",
    "np.random.shuffle(indices_shuffled)\n",
    "\n",
    "data_split = {\n",
    "    \"train\": lambda x: np.isin(x, indices_shuffled),\n",
    "    \"val\": lambda x: np.isin(x, np.arange(ds.indices.shape[0])[5064:5500]),\n",
    "    \"test\": lambda x: np.isin(x, np.arange(ds.indices.shape[0])[5064:]),\n",
    "}\n",
    "\n",
    "dm = LSTSDataset(ds, data_split=data_split, batch_size=32, random_seed=42, num_workers=8)\n",
    "dm.l_patterns = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from s3ts.api.nets.methods import create_model_from_DM, train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  torch.Size([1, 8, 16, 16])\n",
      "Latent shape:  torch.Size([1, 16, 1, 16])\n",
      "[tensor(256), 16, 4]\n"
     ]
    }
   ],
   "source": [
    "model = create_model_from_DM(dm, \"dtw\", \"cnn\", \"mlp\", \"cls\", \"test\", 8, 16, 1, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "   | Name        | Type                 | Params\n",
      "------------------------------------------------------\n",
      "0  | dtw_layer   | DTWLayer             | 768   \n",
      "1  | encoder     | CNN_IMG              | 4.1 K \n",
      "2  | decoder     | MultiLayerPerceptron | 4.2 K \n",
      "3  | flatten     | Flatten              | 0     \n",
      "4  | softmax     | Softmax              | 0     \n",
      "5  | train_acc   | MulticlassAccuracy   | 0     \n",
      "6  | train_f1    | MulticlassF1Score    | 0     \n",
      "7  | train_auroc | MulticlassAUROC      | 0     \n",
      "8  | val_acc     | MulticlassAccuracy   | 0     \n",
      "9  | val_f1      | MulticlassF1Score    | 0     \n",
      "10 | val_auroc   | MulticlassAUROC      | 0     \n",
      "11 | test_acc    | MulticlassAccuracy   | 0     \n",
      "12 | test_f1     | MulticlassF1Score    | 0     \n",
      "13 | test_auroc  | MulticlassAUROC      | 0     \n",
      "------------------------------------------------------\n",
      "9.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "9.1 K     Total params\n",
      "0.036     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 156/156 [00:04<00:00, 38.08it/s, v_num=1, train_loss_step=0.992, val_loss=0.899, val_acc=0.557, val_auroc=0.0908, train_loss_epoch=0.869, train_acc=0.648, train_auroc=0.872]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 156/156 [00:04<00:00, 38.03it/s, v_num=1, train_loss_step=0.992, val_loss=0.899, val_acc=0.557, val_auroc=0.0908, train_loss_epoch=0.869, train_acc=0.648, train_auroc=0.872]\n",
      "Input shape:  torch.Size([1, 8, 16, 16])\n",
      "Latent shape:  torch.Size([1, 16, 1, 16])\n",
      "[tensor(256), 16, 4]\n",
      "Validation DataLoader 0: 100%|██████████| 14/14 [00:00<00:00, 67.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5573394298553467     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_auroc         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09083783626556396    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_f1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5573394298553467     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8994016051292419     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5573394298553467    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_auroc        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09083783626556396   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_f1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5573394298553467    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8994016051292419    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(WrapperModel(\n",
       "   (dtw_layer): DTWLayer()\n",
       "   (encoder): CNN_IMG(\n",
       "     (cnn_0): Sequential(\n",
       "       (0): Conv2d(8, 4, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (1): ReLU()\n",
       "       (2): MaxPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "     )\n",
       "     (cnn_1): Sequential(\n",
       "       (0): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (1): ReLU()\n",
       "       (2): AvgPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0)\n",
       "       (3): Dropout(p=0.35, inplace=False)\n",
       "     )\n",
       "     (cnn_2): Sequential(\n",
       "       (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU()\n",
       "       (3): Dropout(p=0.4, inplace=False)\n",
       "     )\n",
       "     (cnn_3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "   )\n",
       "   (decoder): MultiLayerPerceptron(\n",
       "     (fcn_layer_0): Linear(in_features=256, out_features=16, bias=True)\n",
       "     (act_layer_0): ReLU()\n",
       "     (fcn_out): Linear(in_features=16, out_features=4, bias=True)\n",
       "   )\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (softmax): Softmax(dim=None)\n",
       "   (train_acc): MulticlassAccuracy()\n",
       "   (train_f1): MulticlassF1Score()\n",
       "   (train_auroc): MulticlassAUROC()\n",
       "   (val_acc): MulticlassAccuracy()\n",
       "   (val_f1): MulticlassF1Score()\n",
       "   (val_auroc): MulticlassAUROC()\n",
       "   (test_acc): MulticlassAccuracy()\n",
       "   (test_f1): MulticlassF1Score()\n",
       "   (test_auroc): MulticlassAUROC()\n",
       " ),\n",
       " {'val_acc': 0.5573394298553467,\n",
       "  'val_f1': 0.5573394298553467,\n",
       "  'val_auroc': 0.09083783626556396})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(model=model, dm=dm, max_epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
