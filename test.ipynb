{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from s3ts.helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = get_parser()\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset = \"WISDM\"\n",
    "args.dataset_dir = \"./datasets/\"\n",
    "args.rho = 0.1\n",
    "args.batch_size = 128\n",
    "args.num_workers = 8\n",
    "args.num_medoids = 2\n",
    "args.window_size = 48\n",
    "args.window_stride = 1\n",
    "args.normalize = True\n",
    "args.pattern_size = 24\n",
    "args.compute_n = 250\n",
    "args.subjects_for_test = [30, 31, 32, 33, 34, 35]\n",
    "args.mode = \"img\"\n",
    "args.reduce_imbalance = True\n",
    "args.label_mode = 1\n",
    "args.voting = 1\n",
    "args.overlap = 45\n",
    "args.encoder_architecture = \"cnn_gap\"\n",
    "args.encoder_features = 20\n",
    "args.decoder_architecture = \"mlp\"\n",
    "args.decoder_features = 64\n",
    "args.decoder_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset WISDM with a total of 1096480 observations for window size 48\n",
      "Computing medoids...\n",
      "Computing dissimilarity frames...\n",
      "Using 148133 observations for training and 51459 observations for validation and test\n"
     ]
    }
   ],
   "source": [
    "dm = load_dm(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  torch.Size([1, 12, 24, 48])\n",
      "Latent shape:  torch.Size([1, 80])\n",
      "[tensor(80), 64, 6]\n"
     ]
    }
   ],
   "source": [
    "from s3ts.api.nets.methods import train_model\n",
    "\n",
    "model = get_model(\"test\", args, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type                      | Params\n",
      "---------------------------------------------------------\n",
      "0 | encoder    | CNN_GAP_IMG               | 23.1 K\n",
      "1 | decoder    | MultiLayerPerceptron      | 5.6 K \n",
      "2 | flatten    | Flatten                   | 0     \n",
      "3 | softmax    | Softmax                   | 0     \n",
      "4 | train_cm   | MulticlassConfusionMatrix | 0     \n",
      "5 | val_cm     | MulticlassConfusionMatrix | 0     \n",
      "6 | val_auroc  | MulticlassAUROC           | 0     \n",
      "7 | test_cm    | MulticlassConfusionMatrix | 0     \n",
      "8 | test_auroc | MulticlassAUROC           | 0     \n",
      "---------------------------------------------------------\n",
      "28.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "28.7 K    Total params\n",
      "0.115     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1158/1158 [02:32<00:00,  7.60it/s, v_num=25, train_loss_step=0.464, val_loss=0.938, val_auroc=0.890, val_re=0.601, train_loss_epoch=0.542]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1158/1158 [02:32<00:00,  7.60it/s, v_num=25, train_loss_step=0.464, val_loss=0.938, val_auroc=0.890, val_re=0.601, train_loss_epoch=0.542]\n",
      "Input shape:  torch.Size([1, 12, 24, 48])\n",
      "Latent shape:  torch.Size([1, 80])\n",
      "[tensor(80), 64, 6]\n",
      "Validation DataLoader 0: 100%|██████████| 403/403 [00:24<00:00, 16.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_auroc         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8895742297172546     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_f1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5791109204292297     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9381545782089233     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_pr           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5894643068313599     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_re           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6007785797119141     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_auroc        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8895742297172546    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_f1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5791109204292297    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9381545782089233    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_pr          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5894643068313599    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_re          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6007785797119141    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(WrapperModel(\n",
       "   (encoder): CNN_GAP_IMG(\n",
       "     (cnn_0): Sequential(\n",
       "       (0): Conv2d(12, 20, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
       "       (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU()\n",
       "       (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     )\n",
       "     (cnn_1): Sequential(\n",
       "       (0): Conv2d(20, 20, kernel_size=(4, 4), stride=(1, 1), padding=same)\n",
       "       (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU()\n",
       "       (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     )\n",
       "     (cnn_2): Sequential(\n",
       "       (0): Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
       "       (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU()\n",
       "     )\n",
       "     (last): Sequential(\n",
       "       (0): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "   )\n",
       "   (decoder): MultiLayerPerceptron(\n",
       "     (fcn_layer_0): Linear(in_features=80, out_features=64, bias=True)\n",
       "     (act_layer_0): ReLU()\n",
       "     (fcn_out): Linear(in_features=64, out_features=6, bias=True)\n",
       "   )\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (softmax): Softmax(dim=None)\n",
       "   (train_cm): MulticlassConfusionMatrix()\n",
       "   (val_cm): MulticlassConfusionMatrix()\n",
       "   (val_auroc): MulticlassAUROC()\n",
       "   (test_cm): MulticlassConfusionMatrix()\n",
       "   (test_auroc): MulticlassAUROC()\n",
       " ),\n",
       " {'val_loss': 0.9381545782089233,\n",
       "  'val_auroc': 0.8895742297172546,\n",
       "  'val_pr': 0.5894643068313599,\n",
       "  'val_re': 0.6007785797119141,\n",
       "  'val_f1': 0.5791109204292297})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(dm, model, 1, {\n",
    "    \"default_root_dir\": \"training\",\n",
    "    \"accelerator\": \"auto\",\n",
    "    \"seed\": 42\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssstsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
