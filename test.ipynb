{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, Tensor\n",
    "\n",
    "from s3ts.api.nets.encoders.dtw.dtw_no_matrix import dtw_fast_no_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(45)\n",
    "a = torch.randn(1, 2, 5)\n",
    "b = torch.randn(2, 2, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.jit.script\n",
    "def dtw_compute_full(dtw: torch.Tensor, dist_grad: torch.Tensor, dim: int, w: float) -> torch.Tensor:\n",
    "    '''\n",
    "        dtw of shape (n, k, pattern_len, window_size)\n",
    "        dist_grad of shape (n, k, dims, pattern_len, window_size)\n",
    "        grad of shape (n, k, dims, pattern_len)\n",
    "    '''\n",
    "    n, k, len_pattern, len_window = dtw.shape\n",
    "    # very big tensor\n",
    "    grads = torch.zeros(n, k, dim, len_pattern, len_pattern, len_window, device=dist_grad.device) # shape (n, k, dims, pattern_len, pattern_len, window_size)\n",
    "\n",
    "    temp = torch.cumsum(dist_grad, dim=4)\n",
    "    for i in range(len_pattern):\n",
    "        grads[:, :, :, i, i, :] = temp[:, :, :, i, :]\n",
    "        grads[:, :, :, i, i:, 0] = grads[:, :, :, i, i, :1]\n",
    "\n",
    "    for i in range(1, len_pattern): # pl\n",
    "        for j in range(1, len_window): # ws\n",
    "            path = torch.stack([\n",
    "                w * dtw[:, :, i, j-1],\n",
    "                dtw[:, :, i-1, j],\n",
    "                w * dtw[:, :, i-1, j-1]\n",
    "            ])\n",
    "\n",
    "            value, id = path.min(0)\n",
    "            path0 = id == 0\n",
    "            path1 = id == 2\n",
    "            path2 = id == 1\n",
    "\n",
    "            dtw[:, :, i, j] += value\n",
    "\n",
    "            grads[:, :, :, :, i, j][path0] += w * grads[:, :, :, :, i, j-1][path0]\n",
    "            grads[:, :, :, :, i, j][path1] += grads[:, :, :, :, i-1, j][path1]\n",
    "            grads[:, :, :, :, i, j][path2] += w * grads[:, :, :, :, i-1, j-1][path2]\n",
    "\n",
    "    return grads\n",
    "\n",
    "@torch.jit.script\n",
    "def dtw_compute_no_grad(dtw: torch.Tensor, w: float) -> None:\n",
    "    '''\n",
    "        dtw of shape (n, k, pattern_len, window_size)\n",
    "        grad of shape (n, k, dims, pattern_len)\n",
    "    '''\n",
    "\n",
    "    n, k, len_pattern, len_window = dtw.shape\n",
    "\n",
    "    for i in range(1, len_pattern): # pl\n",
    "        for j in range(1, len_window): # ws\n",
    "            value = torch.minimum(w * torch.minimum(dtw[:, :, i, j-1], dtw[:, :, i-1, j-1]), dtw[:, :, i-1, j])\n",
    "\n",
    "            dtw[:, :, i, j] += value\n",
    "    \n",
    "@torch.jit.script\n",
    "def dtw_fast_full(x: torch.Tensor, y: torch.Tensor, w: float, eps: float = 1e-5, compute_gradients: bool=True):\n",
    "    # shape of x (n, dim, x_len) y (m, dim, y_len)\n",
    "\n",
    "    # performs convolution-like operation, for each kernel the DF\n",
    "    # (of shape (kernel_size, T)) is computed, then summed across channels\n",
    "    # x has shape (batch, c, time_dimension)\n",
    "\n",
    "    # compute pairwise diffs (squared)\n",
    "    p_diff = x[:,None,:,None,:] - y[None,:,:,:,None] # shape (n, n_kernel, d, Kernel_size, T)\n",
    "    euc_d = torch.square(p_diff).sum(2) # shape (n, n_kernel, kernel_size, T)\n",
    "\n",
    "    if compute_gradients:\n",
    "        p_diff /= torch.sqrt(euc_d[:,:, None, :, :] + eps)\n",
    "\n",
    "    # compute dtw\n",
    "    euc_d[:,:,0,:] = torch.cumsum(euc_d[:,:,0,:], dim=2)\n",
    "    euc_d[:,:,:,0] = torch.cumsum(euc_d[:,:,:,0], dim=2)\n",
    "\n",
    "    if compute_gradients:\n",
    "        # p_diff now contains the partial derivatives of DTW[n, k, i, j] wrt K[k, d, i] (dims (n, k, d, i, j))\n",
    "        \n",
    "        grads = dtw_compute_full(euc_d, p_diff, x.shape[1], w) # dims (n, k, d, i, i, j)\n",
    "        \n",
    "        return euc_d.sqrt(), grads\n",
    "    else:\n",
    "        dtw_compute_no_grad(euc_d, w)\n",
    "\n",
    "        return euc_d.sqrt(), None\n",
    "\n",
    "class torch_dtw(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(x: torch.Tensor, y: torch.Tensor, w: float):\n",
    "        DTW, p_diff = dtw_fast_full(x, y, w, compute_gradients=y.requires_grad)\n",
    "        return DTW, p_diff\n",
    "    \n",
    "    @staticmethod\n",
    "    def setup_context(ctx, inputs, output):\n",
    "        DTW, p_diff = output\n",
    "        ctx.save_for_backward(p_diff)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, dtw_grad, p_diff_grad):\n",
    "        # dtw_grad dims (n, k, i, j) p_diff dims (n, k, d, i, i, j)\n",
    "        p_diff, = ctx.saved_tensors\n",
    "        mult = (p_diff * dtw_grad[:, :, None, :, None, :]) # dims (n, k, d, i, i, j)\n",
    "        return None, mult.sum(dim=(-2, -1)).mean(dim=0), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw, grads = dtw_fast_no_image(a, b, 1, compute_gradients=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw, grads = dtw_fast_full(a, b, 1, compute_gradients=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.2995, -0.9950,  0.5440,  0.9148, -0.8579, -0.6878],\n",
       "          [-0.1696, -0.0999, -0.8391,  0.4040, -0.5138, -0.7259]],\n",
       "\n",
       "         [[-0.9568,  1.0000,  0.3197,  0.0070,  0.2462,  0.2867],\n",
       "          [ 0.2908, -0.0061,  0.9475, -1.0000,  0.9692,  0.9580]]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[[-0.6353, -0.2995, -0.7211, -0.3951, -0.3885],\n",
       "            [-0.6353, -0.2995, -0.7211, -0.7211, -0.3885],\n",
       "            [-0.6353, -0.2995, -0.2995, -0.7211, -0.7211],\n",
       "            [-0.6353, -0.6353, -0.2995, -0.7211, -0.7211],\n",
       "            [-0.6353, -0.6353, -0.6353, -0.7211, -0.7211],\n",
       "            [-0.6353, -0.6353, -0.6353, -0.7211, -0.7211]],\n",
       "\n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.9992, -0.9849, -1.9799, -3.8073, -2.1075],\n",
       "            [-0.9992, -0.9849, -0.9849, -3.8073, -3.8073],\n",
       "            [-0.9992, -0.9992, -0.9849, -3.8073, -3.8073],\n",
       "            [-0.9992, -0.9992, -0.9992, -3.8073, -3.8073],\n",
       "            [-0.9992, -0.9992, -0.9992, -3.8073, -3.8073]],\n",
       "\n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.3507,  0.4711,  0.4761,  1.0201,  2.6376],\n",
       "            [-0.3507, -0.3507,  0.4711,  1.0201,  2.6376],\n",
       "            [-0.3507, -0.3507, -0.3507,  1.0201,  1.0201],\n",
       "            [-0.3507, -0.3507, -0.3507,  1.0201,  1.0201]],\n",
       "\n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.5432,  1.5151,  2.2353,  3.0390,  3.9538],\n",
       "            [ 0.5432,  1.5151,  1.5151,  3.0390,  3.0390],\n",
       "            [ 0.5432,  1.5151,  1.5151,  3.0390,  3.0390]],\n",
       "\n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.9958, -1.4100, -2.4011, -2.5287, -3.3866],\n",
       "            [-0.9958, -1.4100, -1.4100, -2.5287, -2.5287]],\n",
       "\n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.9926, -1.2115, -2.1936, -2.1868, -2.8746]]],\n",
       "\n",
       "\n",
       "          [[[ 0.7723, -0.1696,  0.7371, -0.2082,  0.7917],\n",
       "            [ 0.7723, -0.1696,  0.7371,  0.7371,  0.7917],\n",
       "            [ 0.7723, -0.1696, -0.1696,  0.7371,  0.7371],\n",
       "            [ 0.7723,  0.7723, -0.1696,  0.7371,  0.7371],\n",
       "            [ 0.7723,  0.7723,  0.7723,  0.7371,  0.7371],\n",
       "            [ 0.7723,  0.7723,  0.7723,  0.7371,  0.7371]],\n",
       "\n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.0393, -1.0392, -1.1390, -3.2663, -3.0873],\n",
       "            [-0.0393, -1.0392, -1.0392, -3.2663, -3.2663],\n",
       "            [-0.0393, -0.0393, -1.0392, -3.2663, -3.2663],\n",
       "            [-0.0393, -0.0393, -0.0393, -3.2663, -3.2663],\n",
       "            [-0.0393, -0.0393, -0.0393, -3.2663, -3.2663]],\n",
       "\n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.9365,  0.3668,  1.3668,  0.5278,  1.8575],\n",
       "            [ 0.9365,  0.9365,  0.3668,  0.5278,  1.8575],\n",
       "            [ 0.9365,  0.9365,  0.9365,  0.5278,  0.5278],\n",
       "            [ 0.9365,  0.9365,  0.9365,  0.5278,  0.5278]],\n",
       "\n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.8396,  0.6042,  1.2980,  0.7031,  1.1071],\n",
       "            [ 0.8396,  0.6042,  0.6042,  0.7031,  0.7031],\n",
       "            [ 0.8396,  0.6042,  0.6042,  0.7031,  0.7031]],\n",
       "\n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.0917, -1.0019, -1.1349, -2.1267, -2.6405],\n",
       "            [-0.0917, -1.0019, -1.0019, -2.1267, -2.1267]],\n",
       "\n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.1212, -1.0970, -1.2854, -2.2854, -3.0113]]]],\n",
       "\n",
       "\n",
       "\n",
       "         [[[[-0.9568, -0.7536, -1.6244, -1.3627, -0.7061],\n",
       "            [-0.9568, -0.7536, -1.6244, -1.3627, -1.3627],\n",
       "            [-0.9568, -0.9568, -1.6244, -1.6244, -1.3627],\n",
       "            [-0.9568, -0.9568, -0.9568, -1.6244, -1.6244],\n",
       "            [-0.9568, -0.9568, -0.9568, -1.6244, -1.6244],\n",
       "            [-0.9568, -0.9568, -0.9568, -1.6244, -1.6244]],\n",
       "\n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.1928,  1.1927,  1.6187,  2.4477,  5.6246],\n",
       "            [ 0.1928,  0.1928,  1.6187,  1.6187,  5.6246],\n",
       "            [ 0.1928,  0.1928,  0.1928,  1.6187,  1.6187],\n",
       "            [ 0.1928,  0.1928,  0.1928,  1.6187,  1.6187],\n",
       "            [ 0.1928,  0.1928,  0.1928,  1.6187,  1.6187]],\n",
       "\n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.6819, -0.1492,  0.1705,  0.7785,  1.6039],\n",
       "            [-0.6819, -0.1492, -0.1492,  0.7785,  0.7785],\n",
       "            [-0.6819, -0.6819, -0.1492,  0.7785,  0.7785],\n",
       "            [-0.6819, -0.6819, -0.1492,  0.7785,  0.7785]],\n",
       "\n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.8120, -1.4386, -2.1540, -2.1470, -4.9229],\n",
       "            [-0.8120, -0.8120, -2.1540, -2.1470, -4.9229],\n",
       "            [-0.8120, -0.8120, -2.1540, -2.1470, -2.1470]],\n",
       "\n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.5323,  0.1327, -0.1367,  0.2924,  0.5386],\n",
       "            [-0.5323, -0.5323, -0.1367,  0.2924,  0.2924]],\n",
       "\n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.3568,  0.6426,  0.5287,  1.1234,  1.4101]]],\n",
       "\n",
       "\n",
       "          [[[ 0.2908, -0.6883, -0.1967, -1.1619, -1.9159],\n",
       "            [ 0.2908, -0.6883, -0.1967, -1.1619, -1.1619],\n",
       "            [ 0.2908,  0.2908, -0.1967, -0.1967, -1.1619],\n",
       "            [ 0.2908,  0.2908,  0.2908, -0.1967, -0.1967],\n",
       "            [ 0.2908,  0.2908,  0.2908, -0.1967, -0.1967],\n",
       "            [ 0.2908,  0.2908,  0.2908, -0.1967, -0.1967]],\n",
       "\n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.9812,  0.9751,  1.8799,  1.3206,  3.3255],\n",
       "            [ 0.9812,  0.9812,  1.8799,  1.8799,  3.3255],\n",
       "            [ 0.9812,  0.9812,  0.9812,  1.8799,  1.8799],\n",
       "            [ 0.9812,  0.9812,  0.9812,  1.8799,  1.8799],\n",
       "            [ 0.9812,  0.9812,  0.9812,  1.8799,  1.8799]],\n",
       "\n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.7314, -0.1149,  0.8326,  0.7660, -0.1559],\n",
       "            [ 0.7314, -0.1149, -0.1149,  0.7660,  0.7660],\n",
       "            [ 0.7314,  0.7314, -0.1149,  0.7660,  0.7660],\n",
       "            [ 0.7314,  0.7314, -0.1149,  0.7660,  0.7660]],\n",
       "\n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.5837, -0.1956,  0.5032, -0.4968, -0.2162],\n",
       "            [ 0.5837,  0.5837,  0.5032, -0.4968, -0.2162],\n",
       "            [ 0.5837,  0.5837,  0.5032, -0.4968, -0.4968]],\n",
       "\n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.8466,  0.0997,  1.0627,  0.1595,  1.1287],\n",
       "            [ 0.8466,  0.8466,  1.0627,  0.1595,  0.1595]],\n",
       "\n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.9342,  0.8988,  1.8923,  1.0883,  2.0464]]]]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.5585, 1.6327,    inf,    inf,    inf],\n",
       "          [   inf,    inf, 1.7728,    inf,    inf],\n",
       "          [   inf,    inf,    inf, 2.7650,    inf],\n",
       "          [   inf,    inf,    inf,    inf, 3.3739],\n",
       "          [   inf,    inf,    inf,    inf, 3.5688],\n",
       "          [   inf,    inf,    inf,    inf, 3.6651]],\n",
       "\n",
       "         [[0.9022,    inf,    inf,    inf,    inf],\n",
       "          [   inf, 1.7319,    inf,    inf,    inf],\n",
       "          [   inf,    inf, 1.7665,    inf,    inf],\n",
       "          [   inf,    inf,    inf, 2.5299,    inf],\n",
       "          [   inf,    inf,    inf,    inf, 2.6717],\n",
       "          [   inf,    inf,    inf,    inf, 2.9638]]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.5585, 1.6327, 2.0872, 2.7839, 2.8937],\n",
       "          [1.9251, 2.3111, 1.7728, 3.5062, 2.8246],\n",
       "          [2.2920, 2.1137, 2.1079, 2.7650, 2.9191],\n",
       "          [2.6982, 2.8980, 2.7001, 3.6185, 3.3739],\n",
       "          [3.3596, 3.3751, 3.1210, 4.1523, 3.5688],\n",
       "          [3.7131, 3.8596, 3.3255, 4.4251, 3.6651]],\n",
       "\n",
       "         [[0.9022, 1.6903, 1.7581, 3.2890, 3.2952],\n",
       "          [1.9109, 1.7319, 2.4691, 2.9034, 3.4215],\n",
       "          [1.9715, 2.3207, 1.7665, 3.3793, 2.9791],\n",
       "          [2.7682, 2.0845, 2.3754, 2.5299, 2.6941],\n",
       "          [3.1356, 2.1574, 2.4405, 3.0295, 2.6717],\n",
       "          [3.5953, 2.2207, 2.7035, 2.9289, 2.9638]]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtw"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssstsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
