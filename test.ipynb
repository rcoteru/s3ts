{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "import yaml\n",
    "\n",
    "from argparse import ArgumentParser, Namespace\n",
    "\n",
    "from s3ts.api.nets.wrapper import WrapperModel\n",
    "from s3ts.helper_functions import load_dm, str_time\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.utilities.model_summary import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from s3ts.helper_functions import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparam_path = os.path.join(\"./training_cv/img_HARTH_3_5_32_2_bs128_lr0.001_cnn_gap20_mlp32_1_p32_r0.1_syn300/version_0/\", \"hparams.yaml\")\n",
    "train_args = None\n",
    "\n",
    "with open(hparam_path, \"r\") as f:\n",
    "    try:\n",
    "        train_args = Namespace(**eval(yaml.safe_load(f)[\"args\"]))\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args.weight_decayL1 = 0\n",
    "train_args.weight_decayL2 = 0\n",
    "train_args.cached = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset HARTH with a total of 6215293 observations for window size 32\n",
      "Using synthetic shapes...\n",
      "Computing dissimilarity frames...\n",
      "Loading cached dissimilarity frames if available...\n",
      "Using 4272507 observations for training, 1592033 for validation and 350753 observations for test\n"
     ]
    }
   ],
   "source": [
    "dm = load_dm(train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  torch.Size([1, 18, 32, 32])\n",
      "Latent shape:  torch.Size([1, 80])\n",
      "[tensor(80), 32, 12]\n"
     ]
    }
   ],
   "source": [
    "model = get_model(\"test\", train_args, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.cnn_0.conv.weight torch.Size([20, 18, 5, 5])\n",
      "encoder.cnn_0.conv.bias torch.Size([20])\n",
      "encoder.cnn_0.bn.weight torch.Size([20])\n",
      "encoder.cnn_0.bn.bias torch.Size([20])\n",
      "encoder.cnn_1.conv.weight torch.Size([20, 20, 4, 4])\n",
      "encoder.cnn_1.conv.bias torch.Size([20])\n",
      "encoder.cnn_1.bn.weight torch.Size([20])\n",
      "encoder.cnn_1.bn.bias torch.Size([20])\n",
      "encoder.cnn_2.conv.weight torch.Size([40, 20, 3, 3])\n",
      "encoder.cnn_2.conv.bias torch.Size([40])\n",
      "encoder.cnn_2.bn.weight torch.Size([40])\n",
      "encoder.cnn_2.bn.bias torch.Size([40])\n",
      "encoder.last.conv.weight torch.Size([80, 40, 1, 1])\n",
      "encoder.last.conv.bias torch.Size([80])\n",
      "decoder.fcn_layer_0.weight torch.Size([32, 80])\n",
      "decoder.fcn_layer_0.bias torch.Size([32])\n",
      "decoder.fcn_out.weight torch.Size([12, 32])\n",
      "decoder.fcn_out.bias torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    print(n, p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(68.5660, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.square().sum() for name, p in model.named_parameters() if (\"bias\" not in name and \"bn\" not in name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1093.2843, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.abs().sum() for name, p in model.named_parameters() if (\"bias\" not in name and \"bn\" not in name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssstsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
