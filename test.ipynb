{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from s3ts.helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset WISDM with a total of 1096480 observations for window size 48\n",
      "Computing medoids...\n",
      "Computing dissimilarity frames...\n",
      "Loading cached dissimilarity frames if available...\n",
      "Using 443636 observations for training and 154375 observations for validation and test\n"
     ]
    }
   ],
   "source": [
    "dm = load_dmdataset(\"WISDM\", \"./datasets/\", 0.1, 128, 8, 48, 1, True, 48, 250, [30, 31, 32, 33, 34, 35], True, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  torch.Size([1, 12, 48, 48])\n",
      "Latent shape:  torch.Size([1, 40, 5])\n",
      "[tensor(200), 64, 6]\n"
     ]
    }
   ],
   "source": [
    "from s3ts.api.nets.methods import create_model_from_DM, train_model\n",
    "\n",
    "model = create_model_from_DM(dm, \"img\", \"cnn_gap\", \"mlp\", \"cls\", \"test\", 20, 64, 1, 0.001, voting={\"n\": 1, \"rho\": 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type                      | Params\n",
      "---------------------------------------------------------\n",
      "0 | encoder    | CNN_GAP_IMG               | 18.3 K\n",
      "1 | decoder    | MultiLayerPerceptron      | 13.3 K\n",
      "2 | flatten    | Flatten                   | 0     \n",
      "3 | softmax    | Softmax                   | 0     \n",
      "4 | train_cm   | MulticlassConfusionMatrix | 0     \n",
      "5 | val_cm     | MulticlassConfusionMatrix | 0     \n",
      "6 | val_auroc  | MulticlassAUROC           | 0     \n",
      "7 | test_cm    | MulticlassConfusionMatrix | 0     \n",
      "8 | test_auroc | MulticlassAUROC           | 0     \n",
      "---------------------------------------------------------\n",
      "31.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "31.5 K    Total params\n",
      "0.126     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 3466/3466 [07:59<00:00,  7.23it/s, v_num=18, train_loss_step=0.023, val_loss=0.668, val_auroc=0.935, val_re=0.782, train_loss_epoch=0.0813, train_re=0.969] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 3466/3466 [07:59<00:00,  7.23it/s, v_num=18, train_loss_step=0.023, val_loss=0.668, val_auroc=0.935, val_re=0.782, train_loss_epoch=0.0813, train_re=0.969]\n",
      "Input shape:  torch.Size([1, 12, 48, 48])\n",
      "Latent shape:  torch.Size([1, 40, 5])\n",
      "[tensor(200), 64, 6]\n",
      "Validation DataLoader 0: 100%|██████████| 1207/1207 [01:00<00:00, 19.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_auroc         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9592697620391846     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_f1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8081207871437073     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5647413730621338     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_pr           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.850165843963623     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_re           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8028659820556641     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_auroc        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9592697620391846    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_f1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8081207871437073    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5647413730621338    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_pr          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.850165843963623    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_re          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8028659820556641    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(WrapperModel(\n",
       "   (encoder): CNN_GAP_IMG(\n",
       "     (cnn_0): Sequential(\n",
       "       (0): Conv2d(12, 10, kernel_size=(7, 7), stride=(1, 1), padding=same)\n",
       "       (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU()\n",
       "       (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     )\n",
       "     (cnn_1): Sequential(\n",
       "       (0): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
       "       (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU()\n",
       "       (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     )\n",
       "     (cnn_2): Sequential(\n",
       "       (0): Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
       "       (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU()\n",
       "       (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     )\n",
       "   )\n",
       "   (decoder): MultiLayerPerceptron(\n",
       "     (fcn_layer_0): Linear(in_features=200, out_features=64, bias=True)\n",
       "     (act_layer_0): ReLU()\n",
       "     (fcn_out): Linear(in_features=64, out_features=6, bias=True)\n",
       "   )\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (softmax): Softmax(dim=None)\n",
       "   (train_cm): MulticlassConfusionMatrix()\n",
       "   (val_cm): MulticlassConfusionMatrix()\n",
       "   (val_auroc): MulticlassAUROC()\n",
       "   (test_cm): MulticlassConfusionMatrix()\n",
       "   (test_auroc): MulticlassAUROC()\n",
       " ),\n",
       " {'val_re': 0.8028659820556641,\n",
       "  'val_f1': 0.8081207871437073,\n",
       "  'val_auroc': 0.9592697620391846})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(dm, model, 3, {\n",
    "    \"default_root_dir\": \"training\",\n",
    "    \"accelerator\": \"auto\",\n",
    "    \"seed\": 42\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_online = tm.Accuracy(task=\"multiclass\", num_classes=6, average=\"macro\")\n",
    "cm_online = tm.ConfusionMatrix(task=\"multiclass\", num_classes=6)\n",
    "dataloader = dm.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for batch_idx, data in enumerate(dataloader):\n",
    "    preds = model.logits(data[\"series\"])\n",
    "    acc_online(preds, data[\"label\"])\n",
    "    cl = torch.argmax(preds, dim=1)\n",
    "    cm_online(cl, data[\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8273)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_online.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = cm_online.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = cm.diag()\n",
    "FP = cm.sum(0) - TP\n",
    "FN = cm.sum(1) - TP\n",
    "TN = torch.empty(cm.shape[0])\n",
    "for i in range(cm.shape[0]):\n",
    "    TN[i] = cm[:i,:i].sum() + cm[:i,i:].sum() + cm[i:,:i].sum() + cm[i:,i:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP + TN)/(TP + TN + FP + FN)\n",
    "precision = TP/(TP+FP)\n",
    "recall = TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9405, 0.9863, 0.9907, 0.9917, 0.9052, 0.9293])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6781, 0.9370, 0.8843, 0.8330, 0.8169, 0.8146])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8273)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssstsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
