{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.jit.script\n",
    "def dtw_compute_full2(dtw: torch.Tensor, dist_grad: torch.Tensor, w: float) -> torch.Tensor:\n",
    "    '''\n",
    "        dtw of shape (n, k, pattern_len, window_size)\n",
    "        dist_grad of shape (n, k, dims, pattern_len, window_size)\n",
    "        grad of shape (n, k, dims, pl)\n",
    "    '''\n",
    "    n, k, len_pattern, len_window = dtw.shape\n",
    "    grads = torch.zeros((n, k, dist_grad.shape[2], len_pattern), device=dtw.device)\n",
    "\n",
    "    for i in range(1, len_pattern): # pl\n",
    "        for j in range(1, len_window): # ws\n",
    "            value = torch.minimum(w * torch.minimum(dtw[:, :, i, j-1], dtw[:, :, i-1, j-1]), dtw[:, :, i-1, j])\n",
    "\n",
    "            dtw[:, :, i, j] += value\n",
    "\n",
    "    summed_times = 0\n",
    "    for n0 in range(n):\n",
    "        for k0 in range(k):\n",
    "            i0 = len_pattern-1\n",
    "            j0 = len_window-1\n",
    "            while i0+j0>=0:\n",
    "                if i0==0:\n",
    "                    summed_times +=grads[n0, k0, :, i0].numel()\n",
    "                    grads[n0, k0, :, i0] += dist_grad[n0, k0, :, i0, :(j0+1)].sum(1)\n",
    "                    break\n",
    "                if j0==0:\n",
    "                    summed_times += grads[n0, k0, :, i0].numel()\n",
    "                    grads[n0, k0, :, :(i0+1)] += dist_grad[n0, k0, :, :(i0+1), 0]\n",
    "                    break\n",
    "\n",
    "                summed_times += grads[n0, k0, :, i0].numel()\n",
    "                grads[n0, k0, :, i0] += dist_grad[n0, k0, :, i0, j0]\n",
    "\n",
    "                paths = torch.stack([\n",
    "                    dtw[n0, k0, i0, j0-1],\n",
    "                    dtw[n0, k0, i0-1, j0],\n",
    "                    dtw[n0, k0, i0-1, j0-1]            \n",
    "                ])\n",
    "\n",
    "                id = paths.argmin(0)\n",
    "                if id!=0:\n",
    "                    i0-=1\n",
    "                if id!=1:\n",
    "                    j0-=1\n",
    "\n",
    "    print(summed_times)\n",
    "    return grads\n",
    "\n",
    "@torch.jit.script\n",
    "def dtw_compute_no_grad2(dtw: torch.Tensor, w: float) -> None:\n",
    "    '''\n",
    "        dtw of shape (n, k, pattern_len, window_size)\n",
    "        grad of shape (n, k, dims, pattern_len)\n",
    "    '''\n",
    "\n",
    "    n, k, len_pattern, len_window = dtw.shape\n",
    "\n",
    "    for i in range(1, len_pattern): # pl\n",
    "        for j in range(1, len_window): # ws\n",
    "            value = torch.minimum(w * torch.minimum(dtw[:, :, i, j-1], dtw[:, :, i-1, j-1]), dtw[:, :, i-1, j])\n",
    "\n",
    "            dtw[:, :, i, j] += value\n",
    "    \n",
    "@torch.jit.script\n",
    "def dtw_fast_no_image2(x: torch.Tensor, y: torch.Tensor, w: float, eps: float = 1e-5, compute_gradients: bool=True):\n",
    "    # shape of x (n, dim, x_len) y (m, dim, y_len)\n",
    "\n",
    "    # performs convolution-like operation, for each kernel the DF\n",
    "    # (of shape (kernel_size, T)) is computed, then summed across channels\n",
    "    # x has shape (batch, c, time_dimension)\n",
    "\n",
    "    # compute pairwise diffs (squared)\n",
    "    p_diff = x[:,None,:,None,:] - y[None,:,:,:,None] # shape (n, n_kernel, d, Kernel_size, T)\n",
    "    euc_d = torch.square(p_diff).sum(2) # shape (n, n_kernel, kernel_size, T)\n",
    "\n",
    "    if compute_gradients:\n",
    "        p_diff /= torch.sqrt(euc_d[:,:, None, :, :] + eps)\n",
    "\n",
    "    # compute dtw\n",
    "    euc_d[:,:,0,:] = torch.cumsum(euc_d[:,:,0,:], dim=2)\n",
    "    euc_d[:,:,:,0] = torch.cumsum(euc_d[:,:,:,0], dim=2)\n",
    "\n",
    "    if compute_gradients:\n",
    "        # p_diff now contains the partial derivatives of DTW[n, k, i, j] wrt K[k, d, i] (dims (n, k, d, i, j))\n",
    "        \n",
    "        grads = dtw_compute_full2(euc_d, p_diff, w) # dims (n, k, d, i, i, j)\n",
    "        \n",
    "        return euc_d.sqrt(), grads\n",
    "    else:\n",
    "        dtw_compute_no_grad2(euc_d, w)\n",
    "\n",
    "        return euc_d.sqrt(), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.jit.script\n",
    "def dtw_compute_full(dtw: torch.Tensor, dist_grad: torch.Tensor, w: float) -> torch.Tensor:\n",
    "    '''\n",
    "        dtw of shape (n, k, pattern_len, window_size)\n",
    "        dist_grad of shape (n, k, dims, pattern_len, window_size)\n",
    "        grad of shape (n, k, dims, pl)\n",
    "    '''\n",
    "    n, k, len_pattern, len_window = dtw.shape\n",
    "    grads = torch.zeros((n, k, dist_grad.shape[2], len_pattern), device=dtw.device)\n",
    "\n",
    "    for i in range(1, len_pattern): # pl\n",
    "        for j in range(1, len_window): # ws\n",
    "            value = torch.minimum(w * torch.minimum(dtw[:, :, i, j-1], dtw[:, :, i-1, j-1]), dtw[:, :, i-1, j])\n",
    "\n",
    "            dtw[:, :, i, j] += value\n",
    "       \n",
    "    summed_timems = 0\n",
    "    for i0 in range(len_pattern-1, -1, -1):\n",
    "        for j0 in range(len_window-1, -1, -1):\n",
    "            mask = ~torch.isinf(dtw[:, :, i0, j0])\n",
    "            summed_timems += grads[:, :, :, i0][mask].numel()\n",
    "            grads[:, :, :, i0][mask] += dist_grad[:, :, :, i0, j0][mask]\n",
    "\n",
    "            if j0==0 or i0==0:\n",
    "                continue\n",
    "\n",
    "            paths = torch.stack([\n",
    "                dtw[:, :, i0, j0-1],\n",
    "                dtw[:, :, i0-1, j0],\n",
    "                dtw[:, :, i0-1, j0-1]\n",
    "            ])\n",
    "\n",
    "            id = paths.argmin(0)\n",
    "\n",
    "            dtw[:, :, i0, :j0][(id!=0) & mask] = float(\"inf\")\n",
    "            dtw[:, :, :i0, j0][(id!=1) & mask] = float(\"inf\")\n",
    "    print(summed_timems)\n",
    "    return grads\n",
    "\n",
    "@torch.jit.script\n",
    "def dtw_compute_no_grad(dtw: torch.Tensor, w: float) -> None:\n",
    "    '''\n",
    "        dtw of shape (n, k, pattern_len, window_size)\n",
    "        grad of shape (n, k, dims, pattern_len)\n",
    "    '''\n",
    "\n",
    "    n, k, len_pattern, len_window = dtw.shape\n",
    "\n",
    "    for i in range(1, len_pattern): # pl\n",
    "        for j in range(1, len_window): # ws\n",
    "            value = torch.minimum(w * torch.minimum(dtw[:, :, i, j-1], dtw[:, :, i-1, j-1]), dtw[:, :, i-1, j])\n",
    "\n",
    "            dtw[:, :, i, j] += value\n",
    "    \n",
    "@torch.jit.script\n",
    "def dtw_fast_no_image(x: torch.Tensor, y: torch.Tensor, w: float, eps: float = 1e-5, compute_gradients: bool=True):\n",
    "    # shape of x (n, dim, x_len) y (m, dim, y_len)\n",
    "\n",
    "    # performs convolution-like operation, for each kernel the DF\n",
    "    # (of shape (kernel_size, T)) is computed, then summed across channels\n",
    "    # x has shape (batch, c, time_dimension)\n",
    "\n",
    "    # compute pairwise diffs (squared)\n",
    "    p_diff = x[:,None,:,None,:] - y[None,:,:,:,None] # shape (n, n_kernel, d, Kernel_size, T)\n",
    "    euc_d = torch.square(p_diff).sum(2) # shape (n, n_kernel, kernel_size, T)\n",
    "\n",
    "    if compute_gradients:\n",
    "        p_diff /= torch.sqrt(euc_d[:,:, None, :, :] + eps)\n",
    "\n",
    "    # compute dtw\n",
    "    euc_d[:,:,0,:] = torch.cumsum(euc_d[:,:,0,:], dim=2)\n",
    "    euc_d[:,:,:,0] = torch.cumsum(euc_d[:,:,:,0], dim=2)\n",
    "\n",
    "    if compute_gradients:\n",
    "        # p_diff now contains the partial derivatives of DTW[n, k, i, j] wrt K[k, d, i] (dims (n, k, d, i, j))\n",
    "        \n",
    "        grads = dtw_compute_full(euc_d, p_diff, w) # dims (n, k, d, i, i, j)\n",
    "        \n",
    "        return euc_d.sqrt(), grads\n",
    "    else:\n",
    "        dtw_compute_no_grad(euc_d, w)\n",
    "\n",
    "        return euc_d.sqrt(), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1, 2, 5)\n",
    "b = torch.randn(2, 2, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "dtw, grads = dtw_fast_no_image(a, b, 1, compute_gradients=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.0344, 1.4252,    inf,    inf,    inf],\n",
       "          [   inf,    inf, 1.4503,    inf,    inf],\n",
       "          [   inf,    inf,    inf, 1.8254,    inf],\n",
       "          [   inf,    inf,    inf,    inf, 1.8379],\n",
       "          [   inf,    inf,    inf,    inf, 2.2167],\n",
       "          [   inf,    inf,    inf,    inf, 2.7907]],\n",
       "\n",
       "         [[1.9512,    inf,    inf,    inf,    inf],\n",
       "          [3.1375,    inf,    inf,    inf,    inf],\n",
       "          [3.1697,    inf,    inf,    inf,    inf],\n",
       "          [   inf, 3.2347, 3.3188,    inf,    inf],\n",
       "          [   inf,    inf,    inf, 3.3505,    inf],\n",
       "          [   inf,    inf,    inf,    inf, 3.3848]]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.5242,  0.6484,  0.4469, -0.6742, -0.6949,  0.9127],\n",
       "          [ 1.2423, -0.7612, -0.8946,  0.7384,  0.7191, -0.4086]],\n",
       "\n",
       "         [[ 0.9442,  0.8270, -0.9976, -0.2119,  0.7793,  0.9939],\n",
       "          [-0.3293, -0.5622, -0.0694, -0.6793, -0.6267,  0.1103]]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "dtw2, grads2 = dtw_fast_no_image2(a, b, 1, compute_gradients=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.0344, 1.4252, 1.6123, 2.2851, 2.7376],\n",
       "          [1.0378, 1.8451, 1.4503, 1.7515, 2.0362],\n",
       "          [1.9630, 2.7984, 2.4076, 1.8254, 2.2029],\n",
       "          [2.2078, 2.2315, 2.4624, 1.8830, 1.8379],\n",
       "          [2.7859, 2.2417, 2.7192, 2.3990, 2.2167],\n",
       "          [3.1308, 3.5783, 2.8172, 2.8042, 2.7907]],\n",
       "\n",
       "         [[1.9512, 3.9517, 4.4983, 5.1169, 5.7590],\n",
       "          [3.1375, 4.3891, 4.7841, 5.2580, 5.9098],\n",
       "          [3.1697, 3.3288, 3.3588, 3.4224, 3.4751],\n",
       "          [3.2884, 3.2347, 3.3188, 3.4439, 3.5011],\n",
       "          [3.4339, 3.7666, 3.4591, 3.3505, 3.4249],\n",
       "          [3.4807, 3.7467, 3.5414, 3.3679, 3.3848]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.5242,  0.6484,  0.4469, -0.6742, -0.6949,  0.9127],\n",
       "          [ 1.2423, -0.7612, -0.8946,  0.7384,  0.7191, -0.4086]],\n",
       "\n",
       "         [[ 0.9442,  0.8270, -0.9976, -0.2119,  0.7793,  0.9939],\n",
       "          [-0.3293, -0.5622, -0.0694, -0.6793, -0.6267,  0.1103]]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssstsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
